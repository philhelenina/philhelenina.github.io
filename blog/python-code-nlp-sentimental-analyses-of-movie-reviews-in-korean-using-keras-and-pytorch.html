<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>[Python Code - NLP] Sentimental Analyses of Movie Reviews in Korean Using Keras and PyTorch - Cheonkam Jeong</title>
    <link rel="stylesheet" href="../css/style.css">
</head>
<body>
    <article class="blog-post">
        <h1>[Python Code - NLP] Sentimental Analyses of Movie Reviews in Korean Using Keras and PyTorch</h1>
        <p class="post-date">March 31, 2022</p>

        <div><h4 style="text-align: left;"><span style="background-color: white;"><span style="font-family: georgia; font-size: medium;"><b><br /></b></span></span><span><span style="background-color: white; font-family: helvetica;"><span style="font-size: 13px;">In this posting, I am going to compare Keras and PyTorch by giving sentimental analyses of movie reviews in Korean, provided by&nbsp;</span><b style="font-size: 13px;">NAVER</b><span style="font-size: 13px;">. It may be more reasonable to compare Tensorflow and PyTorch because Keras is a high-level deep learning API for Tensorflow while PyTorch is an independent deep learning framework. Nevertheless, Keras is going to be used for the task as it is easier to deal with simple tasks, such as classification, using Keras. I will also explain what Keras and PyTorch are, but as this is a practical tutorial, see the official documents of&nbsp;</span><span style="font-size: 13px;"><a href="https://keras.io/api/">Keras</a>&nbsp;</span><span style="font-size: 13px;">and&nbsp;</span><span style="font-size: 13px;"><a href="https://pytorch.org">PyTorch</a></span><span style="font-size: 13px;">&nbsp;or materials on them for more detailed information on their architecture.</span></span></span></h4></div><div><span><span><span style="background-color: white; font-family: helvetica; font-size: 13px;"><br /></span></span></span></div><div><span><span style="font-family: helvetica; font-size: medium;"><b style="background-color: white;">Keras (with Tensorflow)</b></span></span></div><div><span style="background-color: white; font-family: helvetica;"><span style="font-size: medium;"><b><br /></b></span><span>Keras is a high-level deep learning API for Tensorflow, which provides high-level features for building deep learning models. This means that Keras itself does not deal with low-level calculations, such as tensor manipulation and derivatives. Rather, it utilizes various backend engines, such as Tensorflow, CNTK, etc., for them. Keras consists of many independent modules. There exist independent modules for neural layer, cost function, optimizer, activation function, and the like, and models can be built with them. This is a brief summary of Keras. For more information on Keras, read <i>Deep Learning with Python</i> by Fran√ßois Chollet</span><span><br /></span><span><br /></span></span></div><div><span style="background-color: white; font-family: helvetica;"><span><b>Loading Packages and Data (NAVER movie reviews)</b></span><span><br /></span><span><br /></span></span></div><div><span><span style="background-color: white; font-family: helvetica;">Now, I am going to provide a sentiment analysis of movie reviews in Korean provided by <b>NAVER</b>&nbsp;using Keras. This corpus consists of train and test dataset files. The corpus can be directly loaded from the github source using&nbsp;<b>url-lib</b>, but it was downloaded on a local machine from [here](https://github.com/e9t/nsmc). Both train and test datasets were loaded, and necessary packages were loaded as below. As illustrated, the train dataset consists of document <b>id</b>, <b>document</b>, and <b>label.</b></span></span></div><div><span style="background-color: white; font-family: helvetica; font-weight: bold;"><br /></span></div><div><span style="background-color: white; font-family: helvetica;">The label is binary-encoded: 1 as positive and 0 as negative. After a brief look at the data, the distribution of the data was examined because it is not adequate to do a classification task with imbalanced data. As in cells [9] and [10], positive and negative reviews are well balanced. The null values were removed.</span></div><div><a href="https://blogger.googleusercontent.com/img/a/AVvXsEieEBeOBCFl3qAbcreFx-XItnUfM6lXUHcLUile3OUZbjw1HsEi5oSukvUiNh1Ps9-74AzSfbrJP2cY-9agZkZLYnJtAKHWlIdOinriON90VBpiA3vHsJiSsUQvandLUH5FlPwqhkamOnsDDnwj6TUNakIWJ2PTmXJIGu8QhbGXu2Nd8qUEMVYW_uXM" style="clear: left; float: left; font-weight: 700; margin-bottom: 1em; margin-left: 1em; text-align: center;"><span style="background-color: white; color: black; font-family: helvetica;"><img alt="" data-original-height="1274" data-original-width="1838" height="398" src="https://blogger.googleusercontent.com/img/a/AVvXsEieEBeOBCFl3qAbcreFx-XItnUfM6lXUHcLUile3OUZbjw1HsEi5oSukvUiNh1Ps9-74AzSfbrJP2cY-9agZkZLYnJtAKHWlIdOinriON90VBpiA3vHsJiSsUQvandLUH5FlPwqhkamOnsDDnwj6TUNakIWJ2PTmXJIGu8QhbGXu2Nd8qUEMVYW_uXM=w573-h398" width="573" /></span></a><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/a/AVvXsEieEBeOBCFl3qAbcreFx-XItnUfM6lXUHcLUile3OUZbjw1HsEi5oSukvUiNh1Ps9-74AzSfbrJP2cY-9agZkZLYnJtAKHWlIdOinriON90VBpiA3vHsJiSsUQvandLUH5FlPwqhkamOnsDDnwj6TUNakIWJ2PTmXJIGu8QhbGXu2Nd8qUEMVYW_uXM" style="clear: left; float: left; font-weight: 700; margin-bottom: 1em; margin-left: 1em; text-align: center;"></a><a href="https://blogger.googleusercontent.com/img/a/AVvXsEiEN2dPyIhwvko1e-VPVjSVGtp-zKJCpzn6beSXTLeZVNlqZ48xjgFn27ZI44Bqe_DQh5QfDzLQF80hriTquWFxbnlQwfqCuX8mR-8u9dm9Lw30khpZGyU9i3nA9462IF1C0EQW0aX4F6aZTOsWH-iT-sxOXxT4CuRlC4YpRFscPsq870-xtaBpqVcU" style="clear: left; float: left; margin-bottom: 1em; margin-left: 1em;"><span style="background-color: white; color: black; font-family: helvetica;"><img alt="" data-original-height="1542" data-original-width="1852" height="490" src="https://blogger.googleusercontent.com/img/a/AVvXsEiEN2dPyIhwvko1e-VPVjSVGtp-zKJCpzn6beSXTLeZVNlqZ48xjgFn27ZI44Bqe_DQh5QfDzLQF80hriTquWFxbnlQwfqCuX8mR-8u9dm9Lw30khpZGyU9i3nA9462IF1C0EQW0aX4F6aZTOsWH-iT-sxOXxT4CuRlC4YpRFscPsq870-xtaBpqVcU=w587-h490" width="587" /></span></a></div><div class="separator" style="clear: both; text-align: center;"><span style="background-color: white;"><span style="font-family: helvetica;"><br /></span></span></div><span style="background-color: white; font-family: helvetica;"><span></span><span><br /></span></span><h3 style="text-align: left;"><span><span style="background-color: white; font-family: helvetica;">Data Preprocessing with Korean NLP in Python (KoNLPy)</span></span></h3><span><span style="background-color: white; font-family: helvetica;">The next step was to preprocess data. Non-Hangeul strings were removed as illustrated in cell [13]. White space data also were changed into empty values and then removed as in cell [14]. All the same processes were also applied to the test dataset as illustrated in cell [15]. Then, [Korean stop word list](https://bab2min.tistory.com) was loaded, with which stopwords were removed. Thereafter, all the reviews were tokenized using <a href="https://pypi.org/project/python-mecab-ko/">Mecab</a>&nbsp; in <a href="https://konlpy.org/en/latest/">KoNLPy</a>.&nbsp;There are other tokenizers (or morphological parsers) available in <b>KoNLPy</b>. Among them, <b>Okt (Twitter)&nbsp;</b>is widely used as it provides stems as an option, but in terms of speed, <b>Mecab&nbsp;</b>is second to none, so it was used (Previously, I tested various morphological parsers and compared which one is good for which task. I will write a posting for this if I have some time).</span></span></div><div><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></div><div><span><span style="background-color: white; font-family: helvetica;"><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/a/AVvXsEiWDybl79jfqtsFrAooyJ7QZV3ZLYGF9dItl5PZaVzSthUXNLpJG40_RsrTQDUx0igrOJQjkcky458_CLxj05p62Ca7tne6IaL61Fx0VYlGiKZdcUrLccGwHx7l3MMxp5AiNDVjKb6GyHvejKw7IzUJ3n9j53RJdsceiiPwvi2aDc9kTYz-IQ00qJVd" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><img alt="" data-original-height="1316" data-original-width="1864" height="445" src="https://blogger.googleusercontent.com/img/a/AVvXsEiWDybl79jfqtsFrAooyJ7QZV3ZLYGF9dItl5PZaVzSthUXNLpJG40_RsrTQDUx0igrOJQjkcky458_CLxj05p62Ca7tne6IaL61Fx0VYlGiKZdcUrLccGwHx7l3MMxp5AiNDVjKb6GyHvejKw7IzUJ3n9j53RJdsceiiPwvi2aDc9kTYz-IQ00qJVd=w630-h445" width="630" /></a></div><div class="separator" style="clear: both; text-align: center;"><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/a/AVvXsEjLVloTrVmFe28G4t7n8vKufV71mLoLz7cikxuF_MVMXIJZQe4qwrFUlxGUe06ryoWUO042WaGGYGWU-1LePoaUcM5zBGnors89pnA0xrGAu7qN4qNk5KzYde1D2paEiCU2aSrZTF6XqLTWeA3PTLlDRi_LicVz5zDXqSKYAogXAifnZqlUYYgD6SCx" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><img alt="" data-original-height="946" data-original-width="1866" height="322" src="https://blogger.googleusercontent.com/img/a/AVvXsEjLVloTrVmFe28G4t7n8vKufV71mLoLz7cikxuF_MVMXIJZQe4qwrFUlxGUe06ryoWUO042WaGGYGWU-1LePoaUcM5zBGnors89pnA0xrGAu7qN4qNk5KzYde1D2paEiCU2aSrZTF6XqLTWeA3PTLlDRi_LicVz5zDXqSKYAogXAifnZqlUYYgD6SCx=w636-h322" width="636" /></a></div><br /><br /></div></span></span><h3 style="text-align: left;"><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></h3><h3 style="text-align: left;"><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></h3><h3 style="text-align: left;"><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></h3><h3 style="text-align: left;"><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></h3><h3 style="text-align: left;"><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></h3><h3 style="text-align: left;"><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></h3><h3 style="text-align: left;"><span style="font-family: helvetica;"><br /></span></h3><div><span style="font-family: helvetica;"><br /></span></div><h3 style="text-align: left;"><span><span style="background-color: white; font-family: helvetica;">Integer Encoding and Padding</span></span></h3><span><span style="background-color: white; font-family: helvetica;">Thereafter, all the tokens were encoded as integers using the method <b>fit_on_texts</b>&nbsp;of Keras. The Keras tokenizer returned a vocabulary dictionary based on frequency as in cell [21]. The tokens that occurred less than 3 times in this corpus were discarded as in cell [22], after which the integer encoding was applied again. Then, <b>texts_to_sequences</b>&nbsp;was applied to both train and test datasets. Now, each review consists of indices of tokens as in cell [25], and the labels were transformed into np.array as in cell [26]. The very last step of preprocessing was to do sentence padding. The maximum length of the review was set to 35, and then around 94% of the train data were less than it, as in cell [30]. All the reviews were maded to have the same length (maximum length: 35).&nbsp;</span></span></div><div><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></div><div><span><span style="background-color: white; font-family: helvetica;"><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/a/AVvXsEi2Logy5yTWKxZbOK5yvVkM2YHruSZS2tuIJWFc4Zh1Zh-_XJdgVjrby49qdNCdxjso_068stYIaB_hbCXLMMzeO7JGriSnulAPshXBhV4e5cCwN_z2sj9XRK2jnUCqdbhs7k4GKvhai3s-RSST15kOVi0jrdWPJYey_0LEota-GR_wwXxTcNRkO7WZ" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><img alt="" data-original-height="1344" data-original-width="1886" height="467" src="https://blogger.googleusercontent.com/img/a/AVvXsEi2Logy5yTWKxZbOK5yvVkM2YHruSZS2tuIJWFc4Zh1Zh-_XJdgVjrby49qdNCdxjso_068stYIaB_hbCXLMMzeO7JGriSnulAPshXBhV4e5cCwN_z2sj9XRK2jnUCqdbhs7k4GKvhai3s-RSST15kOVi0jrdWPJYey_0LEota-GR_wwXxTcNRkO7WZ=w655-h467" width="655" /></a></div><div class="separator" style="clear: both; text-align: center;"><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/a/AVvXsEiZyWsV40GsOHPWwqk0YKFVoyprOvHl-XZ6h7kIXunf9ZLqdCJ5j6zv4Uyq68FqkOUcW40usYGfhqLAN7I23FQ6Fh8LgbdGXTM0s8PREwEmnlzSvfIUVWZOCU2uArNh-M1cj9zblnnNV_BZalDzhcqhyFweo5h6pTn3ewZklK2pg0e8mn41nN-vNacL" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><img alt="" data-original-height="640" data-original-width="1868" height="225" src="https://blogger.googleusercontent.com/img/a/AVvXsEiZyWsV40GsOHPWwqk0YKFVoyprOvHl-XZ6h7kIXunf9ZLqdCJ5j6zv4Uyq68FqkOUcW40usYGfhqLAN7I23FQ6Fh8LgbdGXTM0s8PREwEmnlzSvfIUVWZOCU2uArNh-M1cj9zblnnNV_BZalDzhcqhyFweo5h6pTn3ewZklK2pg0e8mn41nN-vNacL=w654-h225" width="654" /></a></div><div class="separator" style="clear: both; text-align: center;"><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/a/AVvXsEjCcveCy2wG_ar-cdcKhP3T9C4ixnPiPplrLdCFxAzxRcabVjMBTjZfszJ71-IucwHuBSHg5t7MFoVbUsKi6-aD57z3ULP_Ixm63Il9o3tQySn6g0uXvQaViAHhL9W1xlPUC908-VNcWSF_RCm621UgnZw99dIdINXNjJUAHGsVyHBqWd4kUKIq8VIX" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><img alt="" data-original-height="1138" data-original-width="1854" height="397" src="https://blogger.googleusercontent.com/img/a/AVvXsEjCcveCy2wG_ar-cdcKhP3T9C4ixnPiPplrLdCFxAzxRcabVjMBTjZfszJ71-IucwHuBSHg5t7MFoVbUsKi6-aD57z3ULP_Ixm63Il9o3tQySn6g0uXvQaViAHhL9W1xlPUC908-VNcWSF_RCm621UgnZw99dIdINXNjJUAHGsVyHBqWd4kUKIq8VIX=w648-h397" width="648" /></a></div><br /><br /></div><br /><br /></div><br /><br /></span></span></div><div><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></div><div><span style="background-color: white; font-family: helvetica;"><span><br /></span><span><br /><br /><br /><br /><br /></span></span><h3 style="text-align: left;"><span><span style="background-color: white; font-family: helvetica;">Implementations of Long Short-Term Memory (LSTM) and Reccurent Unit (GRU)</span></span></h3><span><span style="background-color: white; font-family: helvetica;">The next step was to train the data.&nbsp; This time, Long Short-Term Memory (LSTM) and Gated Reccurent Unit (GRU), types of Recurrent Neural Network (RNN)s, were adopted because the movie review data are sequential (It is also possible to do text classification using Convolutional Neural Network(CNN)s, following <a href="https://arxiv.org/pdf/1408.5882.pdf">Yoon Kim, 2014</a>, but if the data size is big enough, it is recommend to adopt a RNN model). Instead of vanilla RNNs, LSTM and GRU were chosen because RNNs suffer from the problem of vanishing gradients as the number of timesteps increases. LSTM was devised to fix this problem by adding cell state and gates (i.e., forget gate, input gate, and output gate); thus, it is capable of learning long-term dependencies (for more information on the architecture of LSTM, read <a href="https://www.bioinf.jku.at/publications/older/2604.pdf">Hochreiter &amp; Schmidhuber, 1997</a>). GRU, which improved upon LSTM, is also capable of learning long-term dependencies. Instead of using the three gates like LSTM, only two gates (i.e., reset gate and update gate) are used, which made it have simpler structure than LSTM (for more information on the architecture of GRU, read <a href="https://arxiv.org/pdf/1406.1078.pdf">Cho et al., 2014</a>).</span></span></div><div><span style="background-color: white; font-family: helvetica;"><span><br /></span><span>In building input, hidden, and output layers, <b>Sequential()</b>&nbsp;from Keras was called. Other layers needed to be defined separately,&nbsp; so the embedding, LSTM, and fully-connected layers were set as in cell [32]. The embedding layer was set with our vocabularly size, and the dimension of the ourput layer was set to 1 as it is a binary classification in <b>Dense()</b>. Thereafter, <b>EarlyStopping</b>&nbsp;and <b>ModelCheckpoint</b>&nbsp;as callback functions were set, as in cell [33]. Then, <b>Adam</b>&nbsp;was adopted as an optimizer, and binary cross entropy was used as loss function with accuracy rate as the metrics. Lastly, 20% of the train data were used as the validation data, the batch size was set to 64, and the epoch setting was 15. As illustrated in cell [34], training stopped after 6 epochs. It took around 6 minutes to train the data, and the accuracy rate was around 84%. A GRU model was also established with the same parameter settings. After 5 epochs, it stopped. It took around 5 minutes to train the data, and the accuracy rate was around 84%.&nbsp;</span></span></div><div><span><span style="background-color: white; font-family: helvetica;"><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/a/AVvXsEjN8dTVWeyxBzQhV-WjHFvXVbBF0DNwN1t2eDovLQ0OBslVQew_eEUKol_DquGN4AkLD_ZZHW0k9uGgIzx9CgrE-RmmJU6v6kcRQ4PqmZ89HuA6UbYUKnQi7XLAVY6bBMXmdzwjQq6MFJcQEAwTH651ZikS-Om8v_86hHt798po0qEQK7X4qGHl5UJr" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><img alt="" data-original-height="1684" data-original-width="1866" height="563" src="https://blogger.googleusercontent.com/img/a/AVvXsEjN8dTVWeyxBzQhV-WjHFvXVbBF0DNwN1t2eDovLQ0OBslVQew_eEUKol_DquGN4AkLD_ZZHW0k9uGgIzx9CgrE-RmmJU6v6kcRQ4PqmZ89HuA6UbYUKnQi7XLAVY6bBMXmdzwjQq6MFJcQEAwTH651ZikS-Om8v_86hHt798po0qEQK7X4qGHl5UJr=w624-h563" width="624" /></a></div><br /><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/a/AVvXsEiJonpCk8opYJYIN4UWGgXtV9QqFIghGy8g_a1Oea7vvsLOVXZZgCZ0HcRH8vw3o9ymjsSXZEWHgoua_WQoV-w-bx73wyZhcZsC7MlUSyJUnO8O5xfS1QMrcNMTUqA2tNwGoPApldyahJ5fR5d1gYcd3X4SqUD_KcUwOJqwSabjCdFIKbTTJDYNdgGA" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><img alt="" data-original-height="1376" data-original-width="1860" height="465" src="https://blogger.googleusercontent.com/img/a/AVvXsEiJonpCk8opYJYIN4UWGgXtV9QqFIghGy8g_a1Oea7vvsLOVXZZgCZ0HcRH8vw3o9ymjsSXZEWHgoua_WQoV-w-bx73wyZhcZsC7MlUSyJUnO8O5xfS1QMrcNMTUqA2tNwGoPApldyahJ5fR5d1gYcd3X4SqUD_KcUwOJqwSabjCdFIKbTTJDYNdgGA=w628-h465" width="628" /></a></div><br /><br /></span></span><h3 style="text-align: left;"><span><span style="background-color: white; font-family: helvetica;">PyTorch</span></span></h3><span><span style="background-color: white; font-family: helvetica;">PyTorch is a deep learning framework by Facebook for various machine/deep learning tasks. As briefly mentioned above, it may be more reasonable to compare this with Tensorflow in terms of architecture because Keras does not deal with low-level calculations by itself - analogically speaking, PyTorch and Tensorflow are like stick shift while Keras is like automatic drive. Thus, in this section, I briefly explain the major differences of PyTorch and Tensorflow in terms of architecture, and then make a comparison of PyTorch and Keras based more on hands-on experience by performing the same sentiment analysis of the NAVER movie reviews as the above.</span></span></div><div><span><span style="background-color: white; font-family: helvetica;"><br /></span></span><h3 style="text-align: left;"><span><span style="background-color: white; font-family: helvetica;">PyTorch vs. Tensorflow in terms of architecture (rather than Keras)</span></span></h3><span><span style="background-color: white; font-family: helvetica;">PyTorch and Tensorflow are similar in that they both utilize Graphics Processing Unit (GPU) for calculation, operate on tensors, and view models as Directed Acyclic Graphs (DAGs). However, PyTorch and Tensorflow differ on how they can be defined. Specifically, it has been widely recognized that Tensorflow follows <b><i>define and run</i></b>&nbsp;idiom while PyTorch does <b><i>define by run</i></b>. To be specific, the former implies that graph should be defined prior to a model run (thus static graph) while the latter means that model can be defined and changed simultaneously as graph is defined (thus dynamic graph). Another difference (actually more like an advantage of PyTorch) is related to debugging. It is reportedly said that it is sometimes difficult to figure out where errors came from (e.g., either backend parts or more model-specific ones) when using Tensorflow. On the other hand, debugging is eaiser in PyTorch because it is essentially more pythonic and thus gives easy access to codes. Based on what have been explained so far, it seems that PyTorch is the winner. However, there are some advantages of using Tensorflow over PyTorch. One of them is that Tensorflow has a larger user community than PyTorch, so if you are stuck in something, tremendous Tensorflow users can help you!</span></span></div><div><span><span style="background-color: white; font-family: helvetica;"><br /></span></span><h3 style="text-align: left;"><span><span style="background-color: white; font-family: helvetica;">PyTorch Installation</span></span></h3><span style="background-color: white; font-family: helvetica;"><span>As this was the first time for me to use PyTorch, I had to install it. It was easy to install PyTorch. If you go into the official homepage and then click your operating system and the like, it will give you some commands for installation. What you need to is to just type them in your terminal (for Mac user). As the NVIDIA CUDA toolkit does not support Mac OS anymore, CPU should be chosen if your Mac OS is above 10.13 as below. I installed PyTorch using the command below via Terminal. In addition to this, <b>torchtext</b>&nbsp;was installed via Terminal for data handling, and <b>pytorchtools</b>&nbsp;was also installed for early stopping.<br /></span><br /></span></div><div><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></div><div><span><span style="background-color: white; font-family: helvetica;"><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/a/AVvXsEgxaZCfefF-pcA5MXQ7God9gCbyU0JLs26IhKaDCi16yux1jMsLp0rHhvHrJt35lREcb_CEsJs5cTnAOfDsopKKy-H0frueznjjc_ClDdbd4sCT4g-M_g6Kjakxh8bEkr3OJejCrgGKXPk8xFK4I3EkDrXYnhG7AAN5UIm6LqmN7xJf5CcYzCCJO1cG" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><img alt="" data-original-height="626" data-original-width="1612" height="250" src="https://blogger.googleusercontent.com/img/a/AVvXsEgxaZCfefF-pcA5MXQ7God9gCbyU0JLs26IhKaDCi16yux1jMsLp0rHhvHrJt35lREcb_CEsJs5cTnAOfDsopKKy-H0frueznjjc_ClDdbd4sCT4g-M_g6Kjakxh8bEkr3OJejCrgGKXPk8xFK4I3EkDrXYnhG7AAN5UIm6LqmN7xJf5CcYzCCJO1cG=w646-h250" width="646" /></a></div><br /><br /></span></span></div><div><span><span style="background-color: white; font-family: helvetica;"><br /></span></span><h3 style="text-align: left;"><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></h3><h3 style="text-align: left;"><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></h3><h3 style="text-align: left;"><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></h3><h3 style="text-align: left;"><span><span style="background-color: white; font-family: helvetica;">Loading Packages and Data (NAVER movie reviews) &amp; Hyperparameter Setting</span></span></h3><span><span style="background-color: white; font-family: helvetica;">The same <b>NAVER</b>&nbsp;movie review data were used for PyTorch modeling, and the necessary packages were loaded as below. Unlike Keras, several hyperparameters were needed to be set as in cell [2]. The batch size was set to 64, which is the same as the above, the learning rate was set to 0.001, and the number of epoches was set to 10 (It should have set to 15 as above, but as I failed to apply <b>EarlyStopping</b>&nbsp;to PyTorch model because of some loading error. I changed it to 10 for fear of taking too much time.). In addition, device setting was needed, and as CUDA is not available on my local machine, CPU was used (CUDA can be used with Colab). Data were loaded, and after removing null values, they were saved as csv files as in cells [4] and [6]. This treatment is solely practice-driven!</span></span></div><div><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></div><div><span><span style="background-color: white; font-family: helvetica;"><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/a/AVvXsEjZ_x-e4FUB4SVXhfwBPgTSViqkZH1Ahq5KGJ6oiW_3Vbw7edUQC56qBk-6vA6WlTDvWCa1MQtFUw72bmjW-GNQv8zC5hIMEnEl6pg7SmLHzNuF7b9eALf-pK5q61W3Ur1hzslLahjjTMvZNDSa6_yb1wZ2Ut3PAtotwmlAdpk20H85gCILxbcuB9ao" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><img alt="" data-original-height="962" data-original-width="1842" height="343" src="https://blogger.googleusercontent.com/img/a/AVvXsEjZ_x-e4FUB4SVXhfwBPgTSViqkZH1Ahq5KGJ6oiW_3Vbw7edUQC56qBk-6vA6WlTDvWCa1MQtFUw72bmjW-GNQv8zC5hIMEnEl6pg7SmLHzNuF7b9eALf-pK5q61W3Ur1hzslLahjjTMvZNDSa6_yb1wZ2Ut3PAtotwmlAdpk20H85gCILxbcuB9ao=w657-h343" width="657" /></a></div><br /><br /></span></span></div><div><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></div><div><span style="background-color: white; font-family: helvetica;"><span><br /></span><span><br /></span></span></div><div><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></div><div><span><span style="background-color: white; font-family: helvetica;"><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/a/AVvXsEjaVrtqG5o8_l25VtNwwu4avvqYk3V9Ckrcgm4ssuRfvHNQxi4XB-n4HZZdVm9ZrrlitX5_BDXDJ9nN2YZm7yUGRk8zAq2jloXjVNMjF1S62XbQDH4KSxrOpFCTkufrMht_kSgaMbTYpF8inrEzShzoRbixYJUSM1WbA30wBqrDrKVvlPPvmoim_vzp" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><img alt="" data-original-height="988" data-original-width="1842" height="351" src="https://blogger.googleusercontent.com/img/a/AVvXsEjaVrtqG5o8_l25VtNwwu4avvqYk3V9Ckrcgm4ssuRfvHNQxi4XB-n4HZZdVm9ZrrlitX5_BDXDJ9nN2YZm7yUGRk8zAq2jloXjVNMjF1S62XbQDH4KSxrOpFCTkufrMht_kSgaMbTYpF8inrEzShzoRbixYJUSM1WbA30wBqrDrKVvlPPvmoim_vzp=w653-h351" width="653" /></a></div><br /><br /></span></span></div><div><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></div><div><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></div><div><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></div><div><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></div><div><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></div><div><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></div><div><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></div><div><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></div><div><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></div><div><h3 style="text-align: left;"><span><span style="background-color: white; font-family: helvetica;">Data Preprocessing with Torchtext</span></span></h3><span><span style="background-color: white; font-family: helvetica;">The next step was to preprocess data as done above. For this, <b>torchtext</b>&nbsp;was used, by which such necessary preprocessing processes as tokenization, padding, etc. can be done simultaneously because they are provided as parameters, as seen in cell [8]. As with the Keras model, the maximum review length was set to 35, and <b>Mecab</b>&nbsp;was used as a tokenizer. The <b>batch_first</b>&nbsp;was set to <b>True</b>, meaning that mini batch demension should be first, and <b>sequential</b>&nbsp;was set to <b>True</b>&nbsp;for the text while it to <b>False&nbsp;</b>for the label. Then, the format of <b>fields</b>&nbsp;was set as in cell [9]. With this field setting, both train and test data were preprocessed using <b>TabularDataset</b>&nbsp;as in cell [10]. Thereafter, a vocabulary set was built using <b>build_vocab</b>. Only words that occurred at least three times were used for building it, as with the Keras model. Both texts and labels were encoded as integers as in cell [13].&nbsp;</span></span></div><div><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></div><div><span><span style="background-color: white; font-family: helvetica;"><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/a/AVvXsEjKfpuiwPlP7GkQLQahq9Gmra98Ys4MdO1-bVI1pcmM2-gIz-9kkqx9Pk5OjKGAj8ccN6ABWLuM19mWHd22_CBhRaCFcxDfXHvGEn0QGGFbx3PTFc7emVovz1cgwNLWcmnRsi0fmaBJV2RQ6jMpVmea_YCF1Iu3f0zhYIsgjJ_1pPasQwIqm7d9I7-1" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><img alt="" data-original-height="1210" data-original-width="1856" height="415" src="https://blogger.googleusercontent.com/img/a/AVvXsEjKfpuiwPlP7GkQLQahq9Gmra98Ys4MdO1-bVI1pcmM2-gIz-9kkqx9Pk5OjKGAj8ccN6ABWLuM19mWHd22_CBhRaCFcxDfXHvGEn0QGGFbx3PTFc7emVovz1cgwNLWcmnRsi0fmaBJV2RQ6jMpVmea_YCF1Iu3f0zhYIsgjJ_1pPasQwIqm7d9I7-1=w636-h415" width="636" /></a></div><div class="separator" style="clear: both; text-align: center;"><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/a/AVvXsEiGPIiTGjZZTwTirguQzTMkab0WNjE27Xupt2GM2Zq-00bFJSuVRCppSq7SpCVIKGx_BfgDdhtphnJ9VQwDwIxUWAt-EPhVkLUF7dJDB3Gaf_5ABg-4DH2ZNMnzE6sg2C3tD8PtJ17m6SpE9XeDyg1uow_tAWvLHgyCVql7xckNR6IE531Qtv7kyEfG" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><img alt="" data-original-height="1256" data-original-width="1856" height="427" src="https://blogger.googleusercontent.com/img/a/AVvXsEiGPIiTGjZZTwTirguQzTMkab0WNjE27Xupt2GM2Zq-00bFJSuVRCppSq7SpCVIKGx_BfgDdhtphnJ9VQwDwIxUWAt-EPhVkLUF7dJDB3Gaf_5ABg-4DH2ZNMnzE6sg2C3tD8PtJ17m6SpE9XeDyg1uow_tAWvLHgyCVql7xckNR6IE531Qtv7kyEfG=w629-h427" width="629" /></a></div><br /><br /></div><br /><br /></span></span></div><h3 style="text-align: left;"><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></h3><h3 style="text-align: left;"><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></h3><h3 style="text-align: left;"><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></h3><h3 style="text-align: left;"><span><span style="background-color: white; font-family: helvetica;">&nbsp;</span></span></h3><h3 style="text-align: left;"><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></h3><h3 style="text-align: left;"><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></h3><h3 style="text-align: left;"><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></h3><h3 style="text-align: left;"><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></h3><h3 style="text-align: left;"><span><span style="background-color: white; font-family: helvetica;"><br /></span></span></h3><h3 style="text-align: left;"><span><span style="background-color: white; font-family: helvetica;">Implementations of Recurrent Unit (GRU)</span></span></h3><div><span style="background-color: white; font-family: helvetica;"><span>Thereafter, 20% of the train data were assigned as the validation data as in cell [17]. The three iterators for the train, validation, and test data were established&nbsp; for batch learning using <b>BucketIterator</b>&nbsp;as in cell [18]. After checking a few, the iterators were re-loaded as in cell [22]. Now, we need to build a GRU model to train our data. This time, instead of using both LSTM and GRU, only a GRU model was used due to lack of time. The class <b>GRU</b>&nbsp;consits of init, forward, and init_state functions as in cell [23]. Parameters were initiated in init using <b>nn.Module</b>. In the forward function, the first hidden state was set to 0 vector; batch size, sequence length, and hidden state size were returned by GRU (for instance, if the tensor size is [3, 5, 7] and x[:,-1,:] is applied to it, it will return [3, 7]); and only the hidden state at the last time step was considered. Lastly, init\_state function was built for resetting weights. A GRU model was initiated, and <b>Adam</b>&nbsp;was used as an optimizer as in cell [24].</span><span><br /></span><span><br /></span><span>The two functions <b>train&nbsp;</b>and <b>evaluate&nbsp;</b>were defined as in cells [25] and [26]. Cross entropy, to which log function was applied, was used as a loss function, and the accuracy rate was used for the model accessement. The train data were trained as in cell [27]. It took around 22 minutes with 10 epoches, and the test accuracy was around 86%. &nbsp;</span><br /><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/a/AVvXsEhRNCapVjuFuRNjZ-4OpndBzy3p98Tp7xAdzGr5auQgZRU_ZEb6nmAE10PAIQpv2m8SEPSIHJ48nZDXOb_-Fu_zuiMTMXG4TiGAJ2on0qxf4_yNJM1wp7wBPRqL2PXq3LNBYPUP8symlQZnZDa8eKpii5cn32-hnsPtnR4tIFC6q2twnZjTSTulYhHu" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><img alt="" data-original-height="882" data-original-width="1854" height="306" src="https://blogger.googleusercontent.com/img/a/AVvXsEhRNCapVjuFuRNjZ-4OpndBzy3p98Tp7xAdzGr5auQgZRU_ZEb6nmAE10PAIQpv2m8SEPSIHJ48nZDXOb_-Fu_zuiMTMXG4TiGAJ2on0qxf4_yNJM1wp7wBPRqL2PXq3LNBYPUP8symlQZnZDa8eKpii5cn32-hnsPtnR4tIFC6q2twnZjTSTulYhHu=w644-h306" width="644" /></a></div><div class="separator" style="clear: both; text-align: center;"><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/a/AVvXsEj3_itWrX_hvlDETO5kHdD_FrqB6H6ewXF4OSAahdn4Kc6lMSMH7Wr5OoyRfPmIOv5gywSg_6hGO6-FoyieEZffncQ-Trp2iMN90nUonJw1qWUnXfTKMw5OmMRDafB1oVJPhuXKTbMKN4jOrGaGrXd6OlK8F2Rve5yDZLF5qSd-X1oElZzQ2E67HjKV" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><img alt="" data-original-height="974" data-original-width="1860" height="337" src="https://blogger.googleusercontent.com/img/a/AVvXsEj3_itWrX_hvlDETO5kHdD_FrqB6H6ewXF4OSAahdn4Kc6lMSMH7Wr5OoyRfPmIOv5gywSg_6hGO6-FoyieEZffncQ-Trp2iMN90nUonJw1qWUnXfTKMw5OmMRDafB1oVJPhuXKTbMKN4jOrGaGrXd6OlK8F2Rve5yDZLF5qSd-X1oElZzQ2E67HjKV=w641-h337" width="641" /></a></div><br /><br /></div><br /><br /></span></div><div><span><span style="background-color: white; font-family: helvetica;"><br /></span></span><h3 style="text-align: left;"><span><span style="background-color: white; font-family: helvetica;">Keras (with Tensorflow) vs. PyTorch based on hands-on experience</span></span></h3><span style="background-color: white; font-family: helvetica;"><span>The aim of this posting was to compare Keras (with Tensorflow) and PyTorch, for which sentiment analyses of movie reviews in Korean were performed. Based on the time taken to train the data, Keras is the winner (Keras-GRU: around 5 minutes after 5 epochs vs. PyTorch-GRU: around 20 minutes after 10 epochs), but based on the accuracy rate (Keras-GRU: 84% vs. PyTorch-GRU: 86%), PyTorch is the winner. However, it may not be legitimate to judge which is better based on the model accuracy and time taken to train&nbsp; because they were not exactly on the same page. Specifically, these discrepancies might have been caused for the following reasons: stopwords were not removed in the PyTorch model and EarlyStopping was failed to be adapted to it. So, I provide some personal feedback on each framework. &lt;br&gt;</span><span><br /></span><span>Personally, it was easy to perform the task with Keras than with PyTorch mainly because I have some experiences with Keras while this was the first time to use PyTorch, and partly because Keras seems to require less fine-tuning. Moreover, whenever I was stuck, it was easy to find solutions on Stack Overflow. Nevertheless, I strongly felt that PyTorch was more pythonic and object-oriented, and thus if a model is well established, it can be used a kind of template. In a nutshell, both have definitely their own advantages over the other, so it is a matter of taste!</span></span></div><div><span style="background-color: white; font-family: helvetica;"><span><span><br /></span></span><br /></span></div>













































<p style="font-stretch: normal; line-height: normal; margin: 0px;"></p><div class="separator" style="clear: both; font-size: 13px; text-align: center;"><span style="clear: left; float: left; margin-bottom: 1em; margin-left: 1em;"><span style="background-color: white;"><span style="font-family: helvetica;"><img alt="" data-original-height="1268" data-original-width="1854" height="433" src="https://blogger.googleusercontent.com/img/a/AVvXsEiMLMlZX9AYyi71eC9Fp6bIxrhNsjnpOlHJ8dwcKKGuJzAPe_0N9s2BRjnAj_eJFUqyrY84yNRVz7ti_CCSfixp60-4Yw93VEenVjWQMwqXgBu4OGJXPwAwg4eOwY_I75NKmRJiGB7FLhpJnRpgU-b9FJ9cib3N0IaKXAytydIWyIGKyZ-sxPa-874_=w633-h433" width="633" /></span></span></span></div><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/a/AVvXsEisGGiQ7T-CFvbvzmwj7VFslo_ZyPdaP5vcZYlhusOclEOpOiiXEoyqXDzHD--IFDNYtN55n6n0XIOSEiAOnTFrMVs_r5eZlhvkvLzKEmSVEzDp6G3TjU1r2tu7Q_QB18PX9q1qqpHqNZrjEPTYlqKOe3Cy8bEIhMxVmG3V_5p-kZMl_syvVf0_G2YQ" style="clear: left; float: left; margin-bottom: 1em; margin-left: 1em;"><span style="background-color: white; color: black; font-family: helvetica;"><img alt="" data-original-height="938" data-original-width="1856" height="317" src="https://blogger.googleusercontent.com/img/a/AVvXsEisGGiQ7T-CFvbvzmwj7VFslo_ZyPdaP5vcZYlhusOclEOpOiiXEoyqXDzHD--IFDNYtN55n6n0XIOSEiAOnTFrMVs_r5eZlhvkvLzKEmSVEzDp6G3TjU1r2tu7Q_QB18PX9q1qqpHqNZrjEPTYlqKOe3Cy8bEIhMxVmG3V_5p-kZMl_syvVf0_G2YQ=w626-h317" width="626" /></span></a><span style="background-color: white;"><span style="font-family: helvetica; margin-left: 1em; margin-right: 1em;"></span></span></div><div class="separator" style="clear: both; text-align: center;"><span style="background-color: white;"><span style="font-family: helvetica;"><br /></span></span></div><h4 style="text-align: left;"><span style="background-color: white;"><span style="font-family: helvetica;"><br /><span style="caret-color: rgb(255, 255, 255); font-size: 16px; text-align: left;"><span>References<br /></span></span><span style="font-weight: normal;"><span style="caret-color: rgb(255, 255, 255); text-align: left;">Keras architecture: <i>Deep Learning with Python</i>&nbsp;by Fran√ßois Chollet<br /></span><span style="caret-color: rgb(255, 255, 255); text-align: left;">Keras official documentation: &lt;https://keras.io/api/&gt;<br /></span><span style="caret-color: rgb(255, 255, 255); text-align: left;">PyTorch official documentation: &lt;https://pytorch.org/tutorials/&gt;<br /></span><span style="caret-color: rgb(255, 255, 255); text-align: left;">LSTM (Hochreiter &amp; Schmidhuber, 1997): &lt;https://www.bioinf.jku.at/publications/older/2604.pdf&gt;<br /></span><span style="caret-color: rgb(255, 255, 255); text-align: left;">GRU (Cho et al., 2014): &lt;https://arxiv.org/pdf/1406.1078.pdf&gt;<br /></span><span style="caret-color: rgb(255, 255, 255); text-align: left;">Text classification with CNNs (Yoon Kim, 2014): &lt;https://arxiv.org/pdf/1408.5882.pdf&gt;<br /></span><span style="caret-color: rgb(255, 255, 255); text-align: left;">A deep learning tutorial book in Korean: <i>Deep learning starting from the bottm (Korean Edition)</i>&nbsp;by Saito Goki and Dog front map<br /></span><span style="caret-color: rgb(255, 255, 255); text-align: left;">A deep learning tutorial book in Korean: &lt;https://wikidocs.net/book/2788&gt;</span></span></span></span></h4><p></p>
















<div><span style="color: #bf8555;"><br /></span></div>

        <p class="post-meta">
            <strong>Categories:</strong> Python Code, NLP Code
        </p>

        <p class="post-meta">
            <small>Original post: <a href="https://cheonkamjeong.blogspot.com/2022/03/sentimental-analyses-of-movie-reviews.html" target="_blank">https://cheonkamjeong.blogspot.com/2022/03/sentimental-analyses-of-movie-reviews.html</a></small>
        </p>
    </article>

    <!-- Navigation -->
    <nav>
        <ul>
            <li><a href="../index.html">Home</a></li>
            <li><a href="../publications.html">Publications</a></li>
            <li><a href="../blog.html" class="active">Blog</a></li>
        </ul>
    </nav>

    <!-- Footer -->
    <footer>
        <p>&copy; 2025 Cheonkam Jeong. Last updated: October 2025.</p>
    </footer>
</body>
</html>
