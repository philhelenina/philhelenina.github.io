<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>[Book Summary - Speech Technology] Introduction to Speech Technology (Holmes & Holmes, 2001) - Cheonkam Jeong</title>
    <link rel="stylesheet" href="../css/style.css">
</head>
<body>
    <article class="blog-post">
        <h1>[Book Summary - Speech Technology] Introduction to Speech Technology (Holmes & Holmes, 2001)</h1>
        <p class="post-date">December 04, 2022</p>

        <h1 style="caret-color: rgb(0, 0, 0); text-size-adjust: auto;"><span style="font-family: helvetica; font-size: large;">Ch 4. Digital coding of speech</span></h1><ul style="caret-color: rgb(0, 0, 0); text-size-adjust: auto;"><li><span style="font-family: helvetica;">3 things to consider in speech coding: data rate, speech quality, and algorithm complexity</span></li><li><span style="font-family: helvetica;">Human cognitive processes cannot take account of an information rate in excess of a few tens of bis per second, thus implying a ratio of information transmitted to information used of between 1,000 and 10,000</span></li><li><span style="font-family: helvetica;">2 properties of speech communication: the restricted capacity of the human auditory system and the physiology of the speaking mechanism (based on the fact that the signal is known to be produced by a human talker)</span></li><li><span style="font-family: helvetica;">3 coding methods: simple waveform coders, analysis/synthesis systems, and intermediate systems</span></li></ul><h2 style="caret-color: rgb(0, 0, 0); text-size-adjust: auto;"><span style="font-family: helvetica; font-size: medium;">Simple waveform coders</span></h2><ul style="caret-color: rgb(0, 0, 0); text-size-adjust: auto;"><li><span style="font-family: helvetica;">copy the actual shape of the waveform produced by the microphone and its associated analogue circuits</span></li><li><span style="font-family: helvetica;">consist of a band limiting filter, a sampler, and a device for coding the samples</span></li><li><span style="font-family: helvetica;">types of simple waveform coders</span><ol><li><span style="font-family: helvetica;">Pulse code modulation (PCM)i) used for feeding analogue signals into computers or other digital equipment for subsequent processingii) not normally used due to the high required digit rateiii) does not exploit the above two properties (i.e., speech production and/or auditory perception), except for the limited bandwidth</span></li><li><span style="font-family: helvetica;">Deltamodulation: uses its transmitted digital codes to generate a local copy of the input waveform and chooses successive digital codes</span></li></ol></li></ul><h2 style="caret-color: rgb(0, 0, 0); text-size-adjust: auto;"><span style="font-family: helvetica; font-size: medium;">Analysis/synthesis systems (vocoders)</span></h2><ul style="caret-color: rgb(0, 0, 0); text-align: left; text-size-adjust: auto;"><li><span style="font-family: helvetica;">analyze the speech signal in terms of parameters</span></li><li><span style="font-family: helvetica;">the output does not need to resemble the the original waveform in appearance, but should be perceptually similar</span></li><li><span style="font-family: helvetica;">based on a model of speech production</span></li><li><span style="font-family: helvetica;">the data are coded into frames representing speech spectra measured at 10-30 ms</span></li><li><span style="font-family: helvetica;">types of vocoders</span><ol><li><span style="font-family: helvetica;">channel vocoders&nbsp;i) principle: the spectrum is represented by the response of a bank of contiguous variable-gain bandpass filters, and the control signals for the channels are derived by measuring the short-term-average power from a similar set of filters fed with the input speech signal in the transmitter, ii) limitation: need a large number of channels, iii) performance: 15-20 channels reasonable for communication purposes; operating at data rates of around 2,400 bits/s or lower</span></li><li><span style="font-family: helvetica;">sinusoidal coders i) representing the short-term spectrum of a speech signal as a sum of sinusoids specified in terms of frequency, amplitude, and phase (called sinusoidal transform coding (STC), ii) voiced speech and unvoiced speech represented by harmonically related sinusoids for the former and with random phases for the latter, iii) Multi-band excitation (MBE) coding: voiced as a combination of the relevant set of harmonic sinusoids; unvoiced using a frequency-domain method with regard to a whitenoise excitation signaliv) 2,000-4,000 bits/s range</span></li><li><span style="font-family: helvetica;">linear predictive coding (LPC) vocoders</span></li><li><span style="font-family: helvetica;">formant vocoders</span></li></ol></li></ul><h2 style="caret-color: rgb(0, 0, 0); text-size-adjust: auto;"><span style="font-family: helvetica; font-size: medium;">Intermediate systems</span></h2><ul style="caret-color: rgb(0, 0, 0); text-size-adjust: auto;"><li><span style="font-family: helvetica;">utilize both simple waveform coders and analysis/synthesis system</span></li></ul><h1 style="caret-color: rgb(0, 0, 0); text-size-adjust: auto;"><span style="font-family: helvetica; font-size: large;">Ch. 8 Automatic speech recognition</span></h1><h2 style="caret-color: rgb(0, 0, 0); text-size-adjust: auto;"><span style="font-family: helvetica; font-size: medium;">General principles of pattern matching</span></h2><ul style="caret-color: rgb(0, 0, 0); text-size-adjust: auto;"><li><span style="font-family: helvetica;">early methods (e.g., Hyde (1972): rule-based approaches, which was not very successful due to co-articulation and difficulty of phone identification</span></li><li><span style="font-family: helvetica;">pattern-matching techniques: one way is to store example acoustic patterns (called templates) for all the words</span></li></ul><h2 style="caret-color: rgb(0, 0, 0); text-size-adjust: auto;"><span style="font-family: helvetica; font-size: medium;">Distance metrics</span></h2><ul style="caret-color: rgb(0, 0, 0); text-size-adjust: auto;"><li><span style="font-family: helvetica;">Filter-bank analysis: describes the speech as a sequence of feature vectors, which can be compared with stored templates for all the words in the vocabulary using a suitable distance metric</span></li><li><span style="font-family: helvetica;">Normalization</span><ol><li><span style="font-family: helvetica;">adding a small consonant to the measured level before taking logarithms</span></li><li><span style="font-family: helvetica;">the square of the Euclidean distance in the multi-dimensional space</span></li></ol></li><li><span style="font-family: helvetica;">Dynamic time warping (DTW)</span><ul><li><span style="font-family: helvetica;">can deal with sequences of connected words ( ⇒ can solve the end-point detection problem)</span></li><li><span style="font-family: helvetica;">by matching one word on to another in a way which applies the optimum non-linear timescale distortion to achieve the best match at all points</span></li><li><span style="font-family: helvetica;">Score pruning: not allowing paths from relatively badly scoring points to propagate further in the DTW calculation</span></li></ul></li></ul><h1 style="caret-color: rgb(0, 0, 0); text-size-adjust: auto;"><span style="font-family: helvetica; font-size: large;">Speech recognition</span></h1><ul style="caret-color: rgb(0, 0, 0); text-size-adjust: auto;"><li><span style="font-family: helvetica;">Speech recognition: store the representation and choose the best matching</span></li><li><span style="font-family: helvetica;">3 broad kinds of synthesis</span><ol><li><span style="font-family: helvetica;">Parametric: manipulate the acoustic?</span></li><li><span style="font-family: helvetica;">Physical (Frankenstein):</span></li><li><span style="font-family: helvetica;">Concatenative (cheating): using pre-recorded units</span></li></ol></li><li><span style="font-family: helvetica;">The synthesis stage</span><ol><li><span style="font-family: helvetica;">a decoding process: the waveform of the acoustical units must be reconstructed from their coded version</span></li><li><span style="font-family: helvetica;">a concatenation process: the sequence of acoustical units must be concatenated after an appropriate modification of their intrinsic prosody</span></li></ol></li><li><span style="font-family: helvetica;">Types of synthesis</span></li><li><span style="font-family: helvetica;">Concatenative synthesis:&nbsp;synthesize the sounds by concatenating such elementary speech units as diphones and demi-syllables→ Pitch adjustment is a problem</span></li><li><span style="font-family: helvetica;">Some pitch adjustment techniques<br /></span><ol><li><span style="font-family: helvetica;">Linear Predictive Coding (LPC): an encoding technique. Do multiple regression on the wave samples to predict any particular sample from the n samples that precede it.Example) w0, w1, w2, w3, w4, w5, w6, w7, w8, w9 (10-sample windows)c1w0 + c2w1 + c3w2 = w3c1w1 + c2w2 + c3w3 = w4...c1w6 + c2w7 + c3w8 = 29→ calculate c1, c2, and c3 by the autoregression→ can be used to reconstruct waves</span></li><li><span style="font-family: helvetica;">Pitch Synchronous Overlap and Add (PSOLA): a digital signal processing technique. The speech waveform is divided into small overlapping segments, and then they are moved to further apart or closer together, in order to change pitch.</span></li></ol></li></ul><h1 style="caret-color: rgb(0, 0, 0); text-size-adjust: auto;"><span style="font-family: helvetica; font-size: medium;">Ways to do pattern matching</span></h1><ul style="caret-color: rgb(0, 0, 0); text-size-adjust: auto;"><li><span style="font-family: helvetica;">Length</span></li><li><span style="font-family: helvetica;">Filter banks: take a wave, break it into time windows, make a spectrum of each window, and then quantize those spectra into a vector of machines→ But how to deal with the data with the different duration? Dynamic time warping (finding an optimal path between two given (time-dependent) sequences)</span></li></ul><h1 style="caret-color: rgb(0, 0, 0); text-size-adjust: auto;"><span style="font-family: helvetica; font-size: medium;">Front-end analysis</span></h1><ul style="caret-color: rgb(0, 0, 0); text-align: left; text-size-adjust: auto;"><li><span style="font-family: helvetica;">Things to consider: i) naturalness, ii) computational efficiency, and iii) results (performance assessment)</span></li><li><span style="font-family: helvetica;">with regard to filter banks: i) overlapping time windows, ii) amplitude scaling, and iii) frequency scaling→ about iii) frequency scaling:</span><ol><li><span style="font-family: helvetica;">Mels: the idea is that low-frequency differences are precisely than high-frequency differences to humans, so scaling is done accordingly)</span></li><li><span style="font-family: helvetica;">Cepstrum: a way of frequency decomposition for a time window—creating a spectrum via Fourier analysis, log-transform it, and do the Fourier again</span></li><li><span style="font-family: helvetica;">MEL frequency cepstral coefficients (MFCC)</span></li><ol><li><span style="font-family: helvetica;">3-1. 25ms overlapped time windows</span></li><li><span style="font-family: helvetica;">MEL-scaled cepstra</span></li><li><span style="font-family: helvetica;">keep the first cepstral filterbanks</span></li><li><span style="font-family: helvetica;">compute 12 additional delta values (a difference score between a coefficient and its next two horizontal neighbors)</span></li><li><span style="font-family: helvetica;">compute another 12 delta-delta values</span></li></ol></ol></li></ul><h1 style="caret-color: rgb(0, 0, 0); text-size-adjust: auto;"><span style="font-family: helvetica; font-size: medium;">Hidden Markov Models (HMMs)</span></h1><ul style="caret-color: rgb(0, 0, 0); text-size-adjust: auto;"><li><span style="font-family: helvetica;">A generative model that models sequential data stochastically</span></li><li><span style="font-family: helvetica;">Markov model: represents sequence that consists of states as state transition probability matrix</span></li><li><span style="font-family: helvetica;">Markov assumption: the observation at the time t is dependent on the latest r observations</span></li><li><span style="font-family: helvetica;">The basic structure: a finite number of states, a designated start state, a finite alphabet, a finite number of arcs, a probability associated with each arc, and for each state, a probability associated with each symbol</span></li><li><span style="font-family: helvetica;">It is supposed that the current state is hidden and draws out it based on the shown information. The direct cause that results in it is unobservable; in other words, only what resulted from the state(s) can be seen. Keep in mind that what are hidden are not parameters, but continuous states the model goes through.</span></li><li><span style="font-family: helvetica;">P(W|A) = P(A|W)P(W)/P(A), A ⇒ O, W ⇒ lambda, P(A|W) ⇒ P(O|lambda)</span></li><li><span style="font-family: helvetica;">Forward and backward procedures: to calculate the probability given the sequence of the status and the model (lambda)</span></li><li><span style="font-family: helvetica;">The Viterbi algorithm: to find the optimal status sequence to explain the data most well</span></li><li><span style="font-family: helvetica;">Baum-Welch re-estimation procedure: to optimize the lambda (parameters of the model) for maximizing P(O|lambda)</span></li></ul><p style="caret-color: rgb(0, 0, 0); text-size-adjust: auto;"><a href="https://blog.naver.com/jamiet1/221420317965"><span style="font-family: helvetica;">https://blog.naver.com/jamiet1/221420317965</span></a></p><h1 style="caret-color: rgb(0, 0, 0); text-size-adjust: auto;"><span style="font-family: helvetica; font-size: large;">Some concepts</span></h1><ul style="caret-color: rgb(0, 0, 0); text-size-adjust: auto;"><li><span style="font-family: helvetica;">Finite state transducers (FST): a finite state automation (FSA), which produces output as well as reading input, meaning it is useful for parsing while a bare FSA can only be used for recognizing (i.e., pattern matching)</span></li></ul>

        <p class="post-meta">
            <strong>Categories:</strong> Speech Technology, Book Summary
        </p>

        <p class="post-meta">
            <small>Original post: <a href="https://cheonkamjeong.blogspot.com/2022/12/book-summary-introduction-to-speech.html" target="_blank">https://cheonkamjeong.blogspot.com/2022/12/book-summary-introduction-to-speech.html</a></small>
        </p>
    </article>

    <!-- Navigation -->
    <nav>
        <ul>
            <li><a href="../index.html">Home</a></li>
            <li><a href="../publications.html">Publications</a></li>
            <li><a href="../blog.html" class="active">Blog</a></li>
        </ul>
    </nav>

    <!-- Footer -->
    <footer>
        <p>&copy; 2025 Cheonkam Jeong. Last updated: October 2025.</p>
    </footer>
</body>
</html>
